# OpenAI Agents + Firecrawl deep research

# Required for OpenAI model calls used in planner/task splitter/coordinator.
OPENAI_API_KEY=sk-your-openai-key

# Optional: point OpenAI client to a LiteLLM proxy (e.g., for Hugging Face models).
# OPENAI_BASE_URL=http://localhost:4000
# Optional: LiteLLM base URL for Agents SDK (sub-agents/synthesis).
# LITELLM_BASE_URL=http://localhost:4000
# LiteLLM proxy key (defaults to OPENAI_API_KEY or HF_TOKEN if unset).
# LITELLM_API_KEY=proxy-key
# Provider toggle (Agents SDK only): openai (default) or litellm
# LLM_PROVIDER=openai

# Required for Firecrawl tools (`search_web`, `scrape_url`).
FIRECRAWL_API_KEY=fc-your-firecrawl-key

# Optional: Hugging Face token if you swap to HF Inference providers.
HF_TOKEN=hf_your_hf_token

# Optional per-stage model overrides (useful when routing via LiteLLM).
# PLANNER_MODEL=huggingface/meta-llama/Meta-Llama-3-8B-Instruct
# TASK_SPLITTER_MODEL=huggingface/meta-llama/Meta-Llama-3-8B-Instruct
# COORDINATOR_MODEL=huggingface/meta-llama/Meta-Llama-3-8B-Instruct

# Add any local overrides below (e.g., proxy settings, model IDs) as needed.
